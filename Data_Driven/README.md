# ğŸ—ï¸ DOLIBARR DATA-DRIVEN SYSTEM

SystÃ¨me intelligent d'analyse des donnÃ©es BTP basÃ© sur **DataLake**, **DataWarehouse** et **Smart Analytics** avec IA/ML.

## ğŸ›ï¸ Architecture

```
ğŸ“Š Dolibarr MySQL  â†’  ğŸï¸ DataLake  â†’  ğŸ¢ DataWarehouse  â†’  ğŸ§  Smart Analytics
     (Source)         (Stockage)      (StructurÃ©)        (IA/ML Insights)
```

### Composants

- **ğŸ”Œ Dolibarr Connector**: Extraction donnÃ©es depuis tables Dolibarr BTP
- **ğŸï¸ DataLake**: Stockage donnÃ©es brutes (Parquet/CSV/JSON) avec qualitÃ©
- **ğŸ¢ DataWarehouse**: ModÃ¨le dimensionnel optimisÃ© pour analytics
- **ğŸ§  Smart Analytics**: ML/IA pour prÃ©dictions et dÃ©tection d'anomalies

## ğŸš€ Installation

```bash
# 1. Cloner et installer dÃ©pendances
cd Data_Driven
pip install -r requirements.txt

# 2. Configuration base de donnÃ©es
cp .env.example .env
# Ã‰diter .env avec vos paramÃ¨tres MySQL

# 3. Test connexion
python src/main.py extract --test-connection
```

## ğŸ“Š Utilisation

### Commandes Principales

```bash
# Pipeline complet (RecommandÃ©)
python src/main.py pipeline

# Ã‰tapes individuelles
python src/main.py extract        # Extraction DataLake
python src/main.py warehouse      # Chargement DataWarehouse  
python src/main.py analytics      # Smart Analytics & ML

# Utilitaires
python src/main.py status         # Statut systÃ¨me
python src/main.py quality        # Rapport qualitÃ© donnÃ©es
python src/main.py cleanup        # Nettoyage anciennes donnÃ©es
```

### Analytics SpÃ©cifiques

```bash
# Modules d'analyse ciblÃ©s
python src/main.py analytics --module anomalies      # DÃ©tection anomalies
python src/main.py analytics --module segmentation   # Segmentation clients
python src/main.py analytics --module prediction     # PrÃ©diction stock
python src/main.py analytics --module insights       # Insights performance
```

## ğŸ—ï¸ DonnÃ©es Extraites

### Tables Dolibarr BTP
- **Tickets**: `llx_ticket` + extrafields (interventions BTP)
- **Projets**: `llx_projet` + tÃ¢ches (chantiers)
- **Stock**: `llx_stock_mouvement` + produits (matÃ©riel)
- **Interventions**: `llx_actioncomm` (historique)
- **Clients**: `llx_societe` + contacts
- **Factures**: `llx_facture` + lignes

### ModÃ¨le DataWarehouse

**Dimensions:**
- `dim_date`: Calendrier complet
- `dim_customer`: Clients BTP
- `dim_project`: Projets/Chantiers
- `dim_technician`: Techniciens

**Faits:**
- `fact_tickets`: Tickets/Interventions avec mÃ©triques
- `fact_stock`: Mouvements stock avec valorisation

## ğŸ§  FonctionnalitÃ©s IA

### 1. PrÃ©diction DurÃ©e Intervention
```python
# PrÃ©dit la durÃ©e basÃ©e sur historique
prediction = smart_analytics.predict_intervention_duration({
    "intervention_type": "maintenance",
    "estimated_duration": 4,
    "city": "Paris"
})
# â†’ {"predicted_duration": 4.2, "confidence": 0.85}
```

### 2. DÃ©tection Anomalies
- Interventions anormalement longues
- CoÃ»ts aberrants  
- Ã‰carts estimation/rÃ©alitÃ©
- Satisfaction client faible

### 3. Segmentation Clients
- Clients Premium (haut CA)
- Clients FrÃ©quents (volume tickets)
- Clients Ã  Risque (satisfaction faible)
- Nouveaux Clients

### 4. PrÃ©diction Stock
- Consommation prÃ©visionnelle
- Recommandations commandes
- Alertes rupture stock

## ğŸ“ˆ Rapports & KPIs

### Vues Analytiques CrÃ©Ã©es
- `v_tickets_monthly`: Performance mensuelle
- `v_technician_performance`: Performance techniciens
- `v_active_projects`: Projets en cours avec budget

### MÃ©triques SurveillÃ©es
- Temps moyen rÃ©solution tickets
- Satisfaction client (1-5)
- Taux d'anomalies interventions
- Ã‰volution coÃ»ts/budget projets
- Rotation stock matÃ©riel

## ğŸ”„ Automatisation

### Cron Jobs RecommandÃ©s

```bash
# Extraction quotidienne (6h du matin)
0 6 * * * cd /path/to/Data_Driven && python src/main.py extract

# Pipeline complet (dimanche 2h)  
0 2 * * 0 cd /path/to/Data_Driven && python src/main.py pipeline

# Nettoyage mensuel
0 3 1 * * cd /path/to/Data_Driven && python src/main.py cleanup --days 90
```

## ğŸ”§ Configuration

### Variables Environnement (.env)
```bash
# Base Dolibarr
DOLIBARR_DB_HOST=localhost
DOLIBARR_DB_NAME=dolibarr
DOLIBARR_DB_USER=dolibarr_user

# DataWarehouse  
WAREHOUSE_DB_NAME=dolibarr_warehouse
WAREHOUSE_DB_USER=warehouse_user

# Analytics
ML_MODEL_RETENTION_DAYS=90
ANALYTICS_CACHE_HOURS=6
```

## ğŸ“Š Monitoring

### Logs
- `logs/dolibarr_data_driven_YYYY-MM-DD.log`: Logs quotidiens
- Rotation automatique (30 jours rÃ©tention)

### MÃ©triques QualitÃ©
- Score qualitÃ© global (0-100)
- Pourcentage valeurs manquantes
- DÃ©tection doublons
- CohÃ©rence donnÃ©es

## ğŸ” Troubleshooting

```bash
# Test connexions
python src/main.py extract --test-connection

# Statut complet systÃ¨me
python src/main.py status

# Reconstruction warehouse si corruption
python src/main.py warehouse --full-rebuild

# Rapport qualitÃ© dÃ©taillÃ©
python src/main.py quality --days 30
```

## ğŸš€ DÃ©veloppement

### Structure Projet
```
src/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ dolibarr_connector.py    # Extraction Dolibarr
â”‚   â”œâ”€â”€ data_lake.py             # Gestion DataLake
â”‚   â”œâ”€â”€ data_warehouse.py        # ETL DataWarehouse
â”‚   â””â”€â”€ smart_analytics.py       # IA/ML Analytics
â”œâ”€â”€ models/                      # ModÃ¨les ML sauvegardÃ©s
â”œâ”€â”€ config/
â”‚   â””â”€â”€ database.py              # Configuration BDD
â””â”€â”€ main.py                      # CLI principal
```

### Ajout Nouvelles Analyses
1. CrÃ©er mÃ©thode dans `SmartAnalytics`
2. Ajouter dans `run_full_analysis()`
3. Optionnel: nouvelle commande CLI

---

**ğŸ—ï¸ Dolibarr BTP Data-Driven System v1.0.0**  
*Analytics intelligent pour optimiser les interventions BTP*